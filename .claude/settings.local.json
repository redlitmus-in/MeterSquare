{
  "permissions": {
    "allow": [
      "Bash(npm run type-check:*)",
      "Bash(/c/Users/admin/AppData/Local/Programs/Python/Python312/python backend/utils/create_boq_template.py)",
      "Bash(npm run dev:*)",
      "Bash(timeout 5 bash -c 'until curl -s http://localhost:8000/api/sitesupervisor_boq > /dev/null 2>&1; do sleep 1; done; echo \"\"Server is ready\"\"')",
      "Bash(python:*)",
      "Bash(C:UsersadminAppDataLocalProgramsPythonPython312python migrations/create_change_requests_table.py)",
      "Bash(npx tsc:*)",
      "Bash(find:*)",
      "Bash(awk:*)",
      "Bash(cat:*)",
      "Bash(PGPASSWORD=postgres psql:*)",
      "Bash(sed:*)",
      "Bash(\"/c/Users/admin/AppData/Local/Programs/Python/Python312/python\" app.py)",
      "Bash(source venv/bin/activate)",
      "Bash(pip uninstall:*)",
      "Bash(pip install:*)",
      "Bash(sudo apt-get:*)",
      "Bash(flask run:*)",
      "Bash(python3:*)",
      "Bash(psql:*)",
      "Bash(for file in boq_upload_controller.py upload_image_controller.py send_boq_client.py vendor_controller.py settings_controller.py)",
      "Bash(do echo \"=== Checking $file ===\")",
      "Bash(done)",
      "Bash(curl:*)",
      "Bash(pkill:*)",
      "Bash(/c/Users/admin/AppData/Local/Programs/Python/Python312/python:*)",
      "Bash(for func in notify_pm_assigned_to_project notify_se_items_assigned notify_se_completion_request notify_pm_confirms_completion)",
      "Bash(do echo \"=== $func ===\")",
      "Bash(for func in notify_cr_created notify_cr_approved notify_cr_rejected notify_vendor_selected_for_cr notify_cr_purchase_completed)",
      "Bash(for func in notify_day_extension_requested notify_day_extension_approved notify_day_extension_rejected notify_vendor_approved)",
      "Bash(node -c:*)",
      "Bash(while read f)",
      "Bash(do basename \"$f\")",
      "Bash(/home/development1/Desktop/MeterSquare/backend/venv/bin/python:*)",
      "Bash(test:*)",
      "Bash(/home/development1/Desktop/MeterSquare/backend/venv/bin/python3:*)",
      "Bash(lsof:*)",
      "Bash(xargs:*)",
      "Bash(ls:*)",
      "Bash(source venv/Scripts/activate)",
      "Bash(DATABASE_URL=\"postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres\" /home/development1/Desktop/MeterSquare/backend/venv/bin/python:*)",
      "Bash(DATABASE_URL=\"postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres\" /home/development1/Desktop/MeterSquare/backend/venv/bin/python:*)",
      "Bash(DATABASE_URL=\"postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev\\$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres\" /home/development1/Desktop/MeterSquare/backend/venv/bin/python:*)",
      "Bash(DATABASE_URL=\"postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol\\$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres\" /home/development1/Desktop/MeterSquare/backend/venv/bin/python:*)",
      "Bash(npm run build:*)",
      "Bash(grep:*)",
      "Bash(kill:*)",
      "SlashCommand(/security-scan)",
      "Bash(git checkout:*)",
      "Bash(SUPABASE_URL=\"https://cbzdvghmrpsolryzdpxi.supabase.co\" SUPABASE_KEY=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImNiemR2Z2htcnBzb2xyeXpkcHhpIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzMyMjk4MDcsImV4cCI6MjA0ODgwNTgwN30.XpxFXsQNDqvhLtELyJJgAV7Y8jjzKwBMFdyMq-sWnfM\" DATABASE_URL=\"postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres\" python:*)",
      "Bash(SUPABASE_URL=\"https://cbzdvghmrpsolryzdpxi.supabase.co\" SUPABASE_KEY=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImNiemR2Z2htcnBzb2xyeXpkcHhpIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzMyMjk4MDcsImV4cCI6MjA0ODgwNTgwN30.XpxFXsQNDqvhLtELyJJgAV7Y8jjzKwBMFdyMq-sWnfM\" DATABASE_URL=\"postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres\" python -c \"\nfrom app import create_app\nfrom models.change_request import ChangeRequest\n\napp = create_app()\nwith app.app_context():\n    # Get recent CRs\n    crs = ChangeRequest.query.order_by(ChangeRequest.cr_id.desc()).limit(5).all()\n    for cr in crs:\n        print(f''=== CR-{cr.cr_id} ==='')\n        print(f''Overall justification: {cr.justification[:50] if cr.justification else \"\"None\"\"}...'')\n        if cr.sub_items_data and len(cr.sub_items_data) > 0:\n            mat = cr.sub_items_data[0]\n            print(f''First material: {mat.get(\"\"material_name\"\")}'')\n            print(f''Per-material justification: \"\"{mat.get(\"\"justification\"\", \"\"NOT FOUND\"\")}\"\"'')\n        print()\n\")",
      "Bash(SUPABASE_URL=\"https://wgddnoiakkoskbbkbygw.supabase.co\" SUPABASE_KEY=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6IndnZGRub2lha2tvc2tiYmtieWd3Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzA5NTg0MjAsImV4cCI6MjA0NjUzNDQyMH0.aYPiz1p8tkEJmyLT5xNdKlTKL1GiqHLvqDPUtuRiLFo\" DATABASE_URL=\"postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres\" python:*)",
      "Bash(PGPASSWORD=Rameshdev$08 psql:*)",
      "Bash(npx eslint:*)",
      "Bash(npm run lint)",
      "Bash(python3 -m ruff check:*)",
      "Bash(python -m py_compile:*)",
      "Bash(source:*)",
      "Bash(python3 -m py_compile:*)",
      "Bash(npm run lint:*)",
      "Bash(python fix_labor_cost.py:*)",
      "Bash(python -m ruff:*)",
      "Bash(ruff check:*)",
      "Bash(xargs kill:*)",
      "Bash(unzip:*)",
      "Bash(pip3 install:*)",
      "Bash(python socketio_server.py:*)",
      "Bash(bash -c \"source venv/bin/activate && nohup python socketio_server.py > /tmp/backend_server.log 2>&1 & echo $!\")",
      "Bash(bash -c \"source venv/bin/activate && nohup python app.py > /tmp/backend_app.log 2>&1 & echo $!\")",
      "Bash(npx eslint --quiet src/roles/production-manager/pages/StockInPage.tsx)",
      "Bash(timeout 20 npm run dev:*)",
      "Bash(source venv/bin/activate:*)",
      "Bash(source .env)",
      "Bash(set -a)",
      "Bash(set +a)",
      "Bash(DATABASE_URL='postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres' python3:*)",
      "Bash(echo:*)",
      "Bash(DATABASE_URL=\"postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres\" python:*)",
      "Bash(PGPASSWORD=\"Rameshdev\\\\$08\" psql:*)",
      "Bash(netstat:*)",
      "Bash(ss:*)",
      "Bash(DATABASE_URL='postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres' python:*)",
      "Bash(DATABASE_URL='postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres' python:*)",
      "Bash(PGPASSWORD='Meterkol$2025' psql:*)",
      "Bash(python -c \"\nimport psycopg2\nimport os\n\nconn = psycopg2.connect\\(''postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres''\\)\ncursor = conn.cursor\\(\\)\n\n# Get all columns from change_requests table\ncursor.execute\\(\"\"\"\"\"\"\n    SELECT column_name, data_type, character_maximum_length, is_nullable, column_default\n    FROM information_schema.columns\n    WHERE table_name = ''change_requests''\n    ORDER BY ordinal_position;\n\"\"\"\"\"\"\\)\n\nprint\\(''=''*100\\)\nprint\\(''CHANGE_REQUESTS TABLE STRUCTURE \\(Development Database\\)''\\)\nprint\\(''=''*100\\)\nprint\\(f\"\"{''Column Name'':<45} {''Type'':<20} {''Nullable'':<10} {''Default''}\"\"\\)\nprint\\(''-''*100\\)\n\nfor row in cursor.fetchall\\(\\):\n    col_name, data_type, max_length, nullable, default = row\n    if max_length:\n        type_str = f''{data_type}\\({max_length}\\)''\n    else:\n        type_str = data_type\n    default_str = str\\(default\\)[:30] if default else ''''\n    print\\(f''{col_name:<45} {type_str:<20} {nullable:<10} {default_str}''\\)\n\ncursor.close\\(\\)\nconn.close\\(\\)\n\")",
      "Bash(python -c \"\nimport psycopg2\n\nconn = psycopg2.connect\\(''postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres''\\)\ncursor = conn.cursor\\(\\)\n\n# Check for potentially unused columns by counting non-null values\ncursor.execute\\(\"\"\"\"\"\"\n    SELECT \n        COUNT\\(*\\) as total_records,\n        COUNT\\(mep_approved_by_user_id\\) as mep_approved_count,\n        COUNT\\(mep_approved_by_name\\) as mep_approved_name_count,\n        COUNT\\(mep_approval_date\\) as mep_approval_date_count,\n        COUNT\\(vendor_whatsapp_sent_at\\) as whatsapp_count,\n        COUNT\\(vendor_email_sent_date\\) as email_count,\n        COUNT\\(delivery_routing\\) as delivery_routing_count,\n        COUNT\\(vendor_delivered_to_store\\) as vendor_delivered_count,\n        COUNT\\(material_vendor_selections\\) as material_vendor_sel_count,\n        COUNT\\(parent_cr_id\\) as parent_cr_count,\n        COUNT\\(submission_group_id\\) as submission_group_count\n    FROM change_requests\n    WHERE is_deleted = false;\n\"\"\"\"\"\"\\)\n\nresult = cursor.fetchone\\(\\)\n\nprint\\(''=''*80\\)\nprint\\(''CHANGE_REQUESTS COLUMN USAGE ANALYSIS \\(Development Database\\)''\\)\nprint\\(''=''*80\\)\nprint\\(f''Total Change Requests: {result[0]}''\\)\nprint\\(\\)\nprint\\(''Column Usage \\(non-NULL count\\):''\\)\nprint\\(''-''*80\\)\nprint\\(f''  mep_approved_by_user_id: {result[1]} records''\\)\nprint\\(f''  mep_approved_by_name: {result[2]} records''\\)\nprint\\(f''  mep_approval_date: {result[3]} records''\\)\nprint\\(f''  vendor_whatsapp_sent_at: {result[4]} records''\\)\nprint\\(f''  vendor_email_sent_date: {result[5]} records''\\)\nprint\\(f''  delivery_routing: {result[6]} records''\\)\nprint\\(f''  vendor_delivered_to_store: {result[7]} records \\(TRUE count\\)''\\)\nprint\\(f''  material_vendor_selections: {result[8]} records''\\)\nprint\\(f''  parent_cr_id: {result[9]} records \\(sub-CRs\\)''\\)\nprint\\(f''  submission_group_id: {result[10]} records''\\)\nprint\\(''=''*80\\)\n\ncursor.close\\(\\)\nconn.close\\(\\)\n\")",
      "Bash(DATABASE_URL=\"postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev\\\\$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres\" python:*)",
      "Bash(python -c \"\nimport psycopg2\n\nconn = psycopg2.connect\\(''postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres''\\)\ncursor = conn.cursor\\(\\)\n\n# Get total count\ncursor.execute\\(''SELECT COUNT\\(*\\) FROM change_requests WHERE is_deleted = false''\\)\ntotal_count = cursor.fetchone\\(\\)[0]\n\n# Get all columns\ncursor.execute\\(\"\"\"\"\"\"\n    SELECT column_name \n    FROM information_schema.columns\n    WHERE table_name = ''change_requests''\n    AND column_name NOT IN \\(''cr_id'', ''created_at'', ''updated_at'', ''is_deleted''\\)\n    ORDER BY column_name;\n\"\"\"\"\"\"\\)\n\ncolumns = [row[0] for row in cursor.fetchall\\(\\)]\n\nprint\\(''=''*100\\)\nprint\\(f''CHECKING {len\\(columns\\)} COLUMNS IN change_requests TABLE''\\)\nprint\\(f''Total Records: {total_count} \\(excluding deleted\\)''\\)\nprint\\(''=''*100\\)\nprint\\(\\)\n\nunused_columns = []\nlow_usage_columns = []\n\nfor col in columns:\n    # Count non-null values\n    cursor.execute\\(f''SELECT COUNT\\({col}\\) FROM change_requests WHERE is_deleted = false AND {col} IS NOT NULL''\\)\n    non_null_count = cursor.fetchone\\(\\)[0]\n    \n    # For boolean/default columns, check if they have non-default values\n    if non_null_count == 0:\n        unused_columns.append\\(\\(col, non_null_count, 0.0\\)\\)\n    elif non_null_count < total_count * 0.1:  # Less than 10% usage\n        low_usage_columns.append\\(\\(col, non_null_count, \\(non_null_count/total_count\\)*100\\)\\)\n\nprint\\(''❌ COMPLETELY UNUSED COLUMNS \\(0% usage - NEVER used\\):''\\)\nprint\\(''-''*100\\)\nif unused_columns:\n    for col, count, pct in sorted\\(unused_columns\\):\n        print\\(f''  ❌ {col:<50} {count}/{total_count} records \\({pct:.1f}%\\)''\\)\nelse:\n    print\\(''  \\(None found\\)''\\)\n\nprint\\(\\)\nprint\\(''⚠️  LOW USAGE COLUMNS \\(< 10% usage\\):''\\)\nprint\\(''-''*100\\)\nif low_usage_columns:\n    for col, count, pct in sorted\\(low_usage_columns, key=lambda x: x[1]\\):\n        print\\(f''  ⚠️  {col:<50} {count}/{total_count} records \\({pct:.1f}%\\)''\\)\nelse:\n    print\\(''  \\(None found\\)''\\)\n\nprint\\(\\)\nprint\\(''=''*100\\)\nprint\\(f''SUMMARY:''\\)\nprint\\(f''  Total Columns Checked: {len\\(columns\\)}''\\)\nprint\\(f''  Completely Unused: {len\\(unused_columns\\)}''\\)\nprint\\(f''  Low Usage: {len\\(low_usage_columns\\)}''\\)\nprint\\(f''  Well Used: {len\\(columns\\) - len\\(unused_columns\\) - len\\(low_usage_columns\\)}''\\)\nprint\\(''=''*100\\)\n\ncursor.close\\(\\)\nconn.close\\(\\)\n\")",
      "Bash(DATABASE_URL=\"postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev\\\\$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres\" python3:*)",
      "Bash(DATABASE_URL=\"postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres\" venv/bin/python test_validation.py)",
      "Bash(PGPASSWORD=\"Meterkol\\\\$2025\" psql:*)",
      "Bash(python -c \"\nimport psycopg2\n\nconn = psycopg2.connect\\(''postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres''\\)\ncursor = conn.cursor\\(\\)\n\n# Get total count\ncursor.execute\\(''SELECT COUNT\\(*\\) FROM change_requests WHERE is_deleted = false''\\)\ntotal_count = cursor.fetchone\\(\\)[0]\n\n# Check all overhead-related columns\noverhead_columns = [\n    ''item_overhead_allocated'',\n    ''item_overhead_consumed_before'',\n    ''item_overhead_available'',\n    ''overhead_consumed'',\n    ''overhead_balance_impact'',\n    ''original_overhead_allocated'',\n    ''original_overhead_used'',\n    ''original_overhead_remaining'',\n    ''original_overhead_percentage'',\n    ''original_profit_percentage'',\n    ''new_overhead_remaining'',\n    ''percentage_of_item_overhead'',\n    ''profit_impact'',\n    ''new_base_cost'',\n    ''new_total_cost'',\n    ''is_over_budget'',\n    ''cost_increase_amount'',\n    ''cost_increase_percentage''\n]\n\nprint\\(''=''*100\\)\nprint\\(''OVERHEAD & FINANCIAL COLUMNS USAGE ANALYSIS''\\)\nprint\\(''=''*100\\)\nprint\\(f''Total Records: {total_count}''\\)\nprint\\(\\)\n\nunused = []\nused = []\n\nfor col in overhead_columns:\n    # Count records where column has non-zero/non-null value\n    cursor.execute\\(f''''''\n        SELECT COUNT\\(*\\) \n        FROM change_requests \n        WHERE is_deleted = false \n        AND {col} IS NOT NULL \n        AND {col} != 0\n    ''''''\\)\n    non_zero_count = cursor.fetchone\\(\\)[0]\n    \n    percentage = \\(non_zero_count / total_count * 100\\) if total_count > 0 else 0\n    \n    if non_zero_count == 0:\n        unused.append\\(\\(col, non_zero_count, percentage\\)\\)\n    else:\n        used.append\\(\\(col, non_zero_count, percentage\\)\\)\n\nprint\\(''❌ OVERHEAD COLUMNS - NEVER USED \\(Always NULL or 0\\):''\\)\nprint\\(''-''*100\\)\nif unused:\n    for col, count, pct in unused:\n        print\\(f''  ❌ {col:<50} {count}/{total_count} \\({pct:.1f}%\\)''\\)\nelse:\n    print\\(''  \\(All overhead columns are being used!\\)''\\)\n\nprint\\(\\)\nprint\\(''✅ OVERHEAD COLUMNS - ACTIVELY USED:''\\)\nprint\\(''-''*100\\)\nif used:\n    for col, count, pct in sorted\\(used, key=lambda x: x[1], reverse=True\\):\n        print\\(f''  ✅ {col:<50} {count}/{total_count} \\({pct:.1f}%\\)''\\)\n\nprint\\(\\)\nprint\\(''=''*100\\)\nprint\\(f''SUMMARY:''\\)\nprint\\(f''  Total Overhead Columns: {len\\(overhead_columns\\)}''\\)\nprint\\(f''  Unused \\(always 0/NULL\\): {len\\(unused\\)}''\\)\nprint\\(f''  Used: {len\\(used\\)}''\\)\nprint\\(''=''*100\\)\n\ncursor.close\\(\\)\nconn.close\\(\\)\n\")",
      "Bash(python -c \"\nimport psycopg2\n\nconn = psycopg2.connect\\(''postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres''\\)\ncursor = conn.cursor\\(\\)\n\n# Get total count\ncursor.execute\\(''SELECT COUNT\\(*\\) FROM change_requests WHERE is_deleted = false''\\)\ntotal_count = cursor.fetchone\\(\\)[0]\n\n# Numeric overhead columns\nnumeric_overhead_columns = [\n    ''item_overhead_allocated'',\n    ''item_overhead_consumed_before'',\n    ''item_overhead_available'',\n    ''overhead_consumed'',\n    ''overhead_balance_impact'',\n    ''original_overhead_allocated'',\n    ''original_overhead_used'',\n    ''original_overhead_remaining'',\n    ''original_overhead_percentage'',\n    ''original_profit_percentage'',\n    ''new_overhead_remaining'',\n    ''percentage_of_item_overhead'',\n    ''profit_impact'',\n    ''new_base_cost'',\n    ''new_total_cost'',\n    ''cost_increase_amount'',\n    ''cost_increase_percentage''\n]\n\nprint\\(''=''*100\\)\nprint\\(''OVERHEAD & FINANCIAL COLUMNS USAGE ANALYSIS''\\)\nprint\\(''=''*100\\)\nprint\\(f''Total Records: {total_count}''\\)\nprint\\(\\)\n\nunused = []\nused = []\n\nfor col in numeric_overhead_columns:\n    # Count records where column has non-zero/non-null value\n    cursor.execute\\(f''''''\n        SELECT COUNT\\(*\\) \n        FROM change_requests \n        WHERE is_deleted = false \n        AND {col} IS NOT NULL \n        AND {col} != 0\n    ''''''\\)\n    non_zero_count = cursor.fetchone\\(\\)[0]\n    \n    percentage = \\(non_zero_count / total_count * 100\\) if total_count > 0 else 0\n    \n    if non_zero_count == 0:\n        unused.append\\(\\(col, non_zero_count, percentage\\)\\)\n    else:\n        used.append\\(\\(col, non_zero_count, percentage\\)\\)\n\n# Check is_over_budget separately \\(boolean\\)\ncursor.execute\\(''''''\n    SELECT COUNT\\(*\\) \n    FROM change_requests \n    WHERE is_deleted = false \n    AND is_over_budget = true\n''''''\\)\nover_budget_count = cursor.fetchone\\(\\)[0]\nover_budget_pct = \\(over_budget_count / total_count * 100\\) if total_count > 0 else 0\n\nprint\\(''❌ OVERHEAD COLUMNS - NEVER USED \\(Always NULL or 0\\):''\\)\nprint\\(''-''*100\\)\nif unused:\n    for col, count, pct in unused:\n        print\\(f''  ❌ {col:<50} {count}/{total_count} \\({pct:.1f}%\\)''\\)\nelse:\n    print\\(''  ✅ ALL overhead columns have data!''\\)\n\nprint\\(\\)\nprint\\(''✅ OVERHEAD COLUMNS - ACTIVELY USED:''\\)\nprint\\(''-''*100\\)\nif used:\n    for col, count, pct in sorted\\(used, key=lambda x: x[1], reverse=True\\):\n        print\\(f''  ✅ {col:<50} {count}/{total_count} \\({pct:.1f}%\\)''\\)\n\nprint\\(\\)\nprint\\(f''  ✅ is_over_budget \\(boolean\\)                        {over_budget_count}/{total_count} TRUE \\({over_budget_pct:.1f}%\\)''\\)\n\nprint\\(\\)\nprint\\(''=''*100\\)\nprint\\(f''SUMMARY:''\\)\nprint\\(f''  Total Overhead Columns: {len\\(numeric_overhead_columns\\) + 1}''\\)\nprint\\(f''  Unused \\(always 0/NULL\\): {len\\(unused\\)}''\\)\nprint\\(f''  Used: {len\\(used\\) + 1}''\\)\nprint\\(''=''*100\\)\n\ncursor.close\\(\\)\nconn.close\\(\\)\n\")",
      "Bash(DATABASE_URL='postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres' python -c \"\nfrom migrations.remove_unused_columns_dev import run_migration\nrun_migration\\(\\)\n\")",
      "Bash(python -c \"\nimport psycopg2\n\nconn = psycopg2.connect\\(''postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres''\\)\ncursor = conn.cursor\\(\\)\n\n# Count columns before and after\ncursor.execute\\(\"\"\"\"\"\"\n    SELECT COUNT\\(*\\) as total_columns\n    FROM information_schema.columns\n    WHERE table_name = ''change_requests'';\n\"\"\"\"\"\"\\)\n\ncolumn_count = cursor.fetchone\\(\\)[0]\n\nprint\\(''=''*80\\)\nprint\\(''CLEANUP VERIFICATION - change_requests TABLE''\\)\nprint\\(''=''*80\\)\nprint\\(f''Total Columns Remaining: {column_count}''\\)\nprint\\(\\)\nprint\\(''Cleanup Summary:''\\)\nprint\\(''  Original: ~96 columns''\\)\nprint\\(''  Removed: 26 columns''\\)\nprint\\(f''  Current: {column_count} columns''\\)\nprint\\(f''  Reduction: {\\(26/96\\)*100:.1f}% smaller''\\)\nprint\\(''=''*80\\)\n\ncursor.close\\(\\)\nconn.close\\(\\)\n\")",
      "Bash(DATABASE_URL='postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres' python3:*)",
      "Bash(DATABASE_URL='postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres' venv/bin/python3:*)",
      "Bash(DATABASE_URL='postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres' python3 -c \"\nimport psycopg2\nimport os\n\nconn = psycopg2.connect\\(os.getenv\\(''DATABASE_URL''\\)\\)\ncursor = conn.cursor\\(\\)\n\n# Fix the status by trimming whitespace\ncursor.execute\\(''''''UPDATE po_child SET status = TRIM\\(status\\) WHERE id = 5''''''\\)\nconn.commit\\(\\)\n\ncursor.execute\\(''''''SELECT id, status, length\\(status\\) FROM po_child WHERE id = 5''''''\\)\nresult = cursor.fetchone\\(\\)\nif result:\n    print\\(f''✅ Fixed! ID: {result[0]}, Status: [{result[1]}], Length: {result[2]}''\\)\n\ncursor.close\\(\\)\nconn.close\\(\\)\n\")",
      "Bash(DATABASE_URL='postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres' python3 -c \"\nimport psycopg2\nimport os\n\nconn = psycopg2.connect\\(os.getenv\\(''DATABASE_URL''\\)\\)\ncursor = conn.cursor\\(\\)\n\n# Fix the status by replacing it completely\ncursor.execute\\(''''''UPDATE po_child SET status = ''vendor_approved'' WHERE id = 5''''''\\)\nconn.commit\\(\\)\n\ncursor.execute\\(''''''SELECT id, status, length\\(status\\) FROM po_child WHERE id = 5''''''\\)\nresult = cursor.fetchone\\(\\)\nif result:\n    print\\(f''✅ Fixed! ID: {result[0]}, Status: [{result[1]}], Length: {result[2]}''\\)\n\ncursor.close\\(\\)\nconn.close\\(\\)\n\")",
      "Bash(npx tsc --noEmit)",
      "Bash(PGPASSWORD=\"${DATABASE_PASSWORD}\" psql:*)"
    ],
    "deny": [],
    "ask": []
  },
  "hooks": {
    "PostToolUse": [
      {
        "matcher": "Edit",
        "hooks": [
          {
            "type": "prompt",
            "prompt": "A code edit was just made. Remind the developer: 'Code changed! Consider running the codebase-auditor agent to review changes for errors, duplicates, and best practices.'",
            "statusMessage": "Checking code change..."
          }
        ]
      },
      {
        "matcher": "Write",
        "hooks": [
          {
            "type": "prompt",
            "prompt": "A new file was just written. Remind the developer: 'New file created! Consider running the codebase-auditor agent to review for errors, duplicates, and best practices.'",
            "statusMessage": "Checking new file..."
          }
        ]
      }
    ]
  }
}
