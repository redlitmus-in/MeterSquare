{
  "permissions": {
    "allow": [
      "Bash(npm run type-check:*)",
      "Bash(/c/Users/admin/AppData/Local/Programs/Python/Python312/python backend/utils/create_boq_template.py)",
      "Bash(npm run dev:*)",
      "Bash(timeout 5 bash -c 'until curl -s http://localhost:8000/api/sitesupervisor_boq > /dev/null 2>&1; do sleep 1; done; echo \"\"Server is ready\"\"')",
      "Bash(python:*)",
      "Bash(C:UsersadminAppDataLocalProgramsPythonPython312python migrations/create_change_requests_table.py)",
      "Bash(npx tsc:*)",
      "Bash(find:*)",
      "Bash(awk:*)",
      "Bash(cat:*)",
      "Bash(PGPASSWORD=postgres psql:*)",
      "Bash(sed:*)",
      "Bash(\"/c/Users/admin/AppData/Local/Programs/Python/Python312/python\" app.py)",
      "Bash(source venv/bin/activate)",
      "Bash(pip uninstall:*)",
      "Bash(pip install:*)",
      "Bash(sudo apt-get:*)",
      "Bash(flask run:*)",
      "Bash(python3:*)",
      "Bash(psql:*)",
      "Bash(for file in boq_upload_controller.py upload_image_controller.py send_boq_client.py vendor_controller.py settings_controller.py)",
      "Bash(do echo \"=== Checking $file ===\")",
      "Bash(done)",
      "Bash(curl:*)",
      "Bash(pkill:*)",
      "Bash(/c/Users/admin/AppData/Local/Programs/Python/Python312/python:*)",
      "Bash(for func in notify_pm_assigned_to_project notify_se_items_assigned notify_se_completion_request notify_pm_confirms_completion)",
      "Bash(do echo \"=== $func ===\")",
      "Bash(for func in notify_cr_created notify_cr_approved notify_cr_rejected notify_vendor_selected_for_cr notify_cr_purchase_completed)",
      "Bash(for func in notify_day_extension_requested notify_day_extension_approved notify_day_extension_rejected notify_vendor_approved)",
      "Bash(node -c:*)",
      "Bash(while read f)",
      "Bash(do basename \"$f\")",
      "Bash(/home/development1/Desktop/MeterSquare/backend/venv/bin/python:*)",
      "Bash(test:*)",
      "Bash(/home/development1/Desktop/MeterSquare/backend/venv/bin/python3:*)",
      "Bash(lsof:*)",
      "Bash(xargs:*)",
      "Bash(ls:*)",
      "Bash(source venv/Scripts/activate)",
      "Bash(DATABASE_URL=\"postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres\" /home/development1/Desktop/MeterSquare/backend/venv/bin/python:*)",
      "Bash(DATABASE_URL=\"postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres\" /home/development1/Desktop/MeterSquare/backend/venv/bin/python:*)",
      "Bash(DATABASE_URL=\"postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev\\$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres\" /home/development1/Desktop/MeterSquare/backend/venv/bin/python:*)",
      "Bash(DATABASE_URL=\"postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol\\$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres\" /home/development1/Desktop/MeterSquare/backend/venv/bin/python:*)",
      "Bash(npm run build:*)",
      "Bash(grep:*)",
      "Bash(kill:*)",
      "SlashCommand(/security-scan)",
      "Bash(git checkout:*)",
      "Bash(SUPABASE_URL=\"https://cbzdvghmrpsolryzdpxi.supabase.co\" SUPABASE_KEY=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImNiemR2Z2htcnBzb2xyeXpkcHhpIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzMyMjk4MDcsImV4cCI6MjA0ODgwNTgwN30.XpxFXsQNDqvhLtELyJJgAV7Y8jjzKwBMFdyMq-sWnfM\" DATABASE_URL=\"postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres\" python:*)",
      "Bash(SUPABASE_URL=\"https://cbzdvghmrpsolryzdpxi.supabase.co\" SUPABASE_KEY=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImNiemR2Z2htcnBzb2xyeXpkcHhpIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzMyMjk4MDcsImV4cCI6MjA0ODgwNTgwN30.XpxFXsQNDqvhLtELyJJgAV7Y8jjzKwBMFdyMq-sWnfM\" DATABASE_URL=\"postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres\" python -c \"\nfrom app import create_app\nfrom models.change_request import ChangeRequest\n\napp = create_app()\nwith app.app_context():\n    # Get recent CRs\n    crs = ChangeRequest.query.order_by(ChangeRequest.cr_id.desc()).limit(5).all()\n    for cr in crs:\n        print(f''=== CR-{cr.cr_id} ==='')\n        print(f''Overall justification: {cr.justification[:50] if cr.justification else \"\"None\"\"}...'')\n        if cr.sub_items_data and len(cr.sub_items_data) > 0:\n            mat = cr.sub_items_data[0]\n            print(f''First material: {mat.get(\"\"material_name\"\")}'')\n            print(f''Per-material justification: \"\"{mat.get(\"\"justification\"\", \"\"NOT FOUND\"\")}\"\"'')\n        print()\n\")",
      "Bash(SUPABASE_URL=\"https://wgddnoiakkoskbbkbygw.supabase.co\" SUPABASE_KEY=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6IndnZGRub2lha2tvc2tiYmtieWd3Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzA5NTg0MjAsImV4cCI6MjA0NjUzNDQyMH0.aYPiz1p8tkEJmyLT5xNdKlTKL1GiqHLvqDPUtuRiLFo\" DATABASE_URL=\"postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres\" python:*)",
      "Bash(PGPASSWORD=Rameshdev$08 psql:*)",
      "Bash(npx eslint:*)",
      "Bash(npm run lint)",
      "Bash(python3 -m ruff check:*)",
      "Bash(python -m py_compile:*)",
      "Bash(source:*)",
      "Bash(python3 -m py_compile:*)",
      "Bash(npm run lint:*)",
      "Bash(python fix_labor_cost.py:*)",
      "Bash(python -m ruff:*)",
      "Bash(ruff check:*)",
      "Bash(xargs kill:*)",
      "Bash(unzip:*)",
      "Bash(pip3 install:*)",
      "Bash(python socketio_server.py:*)",
      "Bash(bash -c \"source venv/bin/activate && nohup python socketio_server.py > /tmp/backend_server.log 2>&1 & echo $!\")",
      "Bash(bash -c \"source venv/bin/activate && nohup python app.py > /tmp/backend_app.log 2>&1 & echo $!\")",
      "Bash(npx eslint --quiet src/roles/production-manager/pages/StockInPage.tsx)",
      "Bash(timeout 20 npm run dev:*)",
      "Bash(source venv/bin/activate:*)",
      "Bash(source .env)",
      "Bash(set -a)",
      "Bash(set +a)",
      "Bash(DATABASE_URL='postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres' python3:*)",
      "Bash(echo:*)",
      "Bash(DATABASE_URL=\"postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres\" python:*)",
      "Bash(PGPASSWORD=\"Rameshdev\\\\$08\" psql:*)",
      "Bash(netstat:*)",
      "Bash(ss:*)",
      "Bash(DATABASE_URL='postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres' python:*)",
      "Bash(DATABASE_URL='postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres' python:*)",
      "Bash(PGPASSWORD='Meterkol$2025' psql:*)",
      "Bash(python -c \"\nimport psycopg2\nimport os\n\nconn = psycopg2.connect\\(''postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres''\\)\ncursor = conn.cursor\\(\\)\n\n# Get all columns from change_requests table\ncursor.execute\\(\"\"\"\"\"\"\n    SELECT column_name, data_type, character_maximum_length, is_nullable, column_default\n    FROM information_schema.columns\n    WHERE table_name = ''change_requests''\n    ORDER BY ordinal_position;\n\"\"\"\"\"\"\\)\n\nprint\\(''=''*100\\)\nprint\\(''CHANGE_REQUESTS TABLE STRUCTURE \\(Development Database\\)''\\)\nprint\\(''=''*100\\)\nprint\\(f\"\"{''Column Name'':<45} {''Type'':<20} {''Nullable'':<10} {''Default''}\"\"\\)\nprint\\(''-''*100\\)\n\nfor row in cursor.fetchall\\(\\):\n    col_name, data_type, max_length, nullable, default = row\n    if max_length:\n        type_str = f''{data_type}\\({max_length}\\)''\n    else:\n        type_str = data_type\n    default_str = str\\(default\\)[:30] if default else ''''\n    print\\(f''{col_name:<45} {type_str:<20} {nullable:<10} {default_str}''\\)\n\ncursor.close\\(\\)\nconn.close\\(\\)\n\")",
      "Bash(python -c \"\nimport psycopg2\n\nconn = psycopg2.connect\\(''postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres''\\)\ncursor = conn.cursor\\(\\)\n\n# Check for potentially unused columns by counting non-null values\ncursor.execute\\(\"\"\"\"\"\"\n    SELECT \n        COUNT\\(*\\) as total_records,\n        COUNT\\(mep_approved_by_user_id\\) as mep_approved_count,\n        COUNT\\(mep_approved_by_name\\) as mep_approved_name_count,\n        COUNT\\(mep_approval_date\\) as mep_approval_date_count,\n        COUNT\\(vendor_whatsapp_sent_at\\) as whatsapp_count,\n        COUNT\\(vendor_email_sent_date\\) as email_count,\n        COUNT\\(delivery_routing\\) as delivery_routing_count,\n        COUNT\\(vendor_delivered_to_store\\) as vendor_delivered_count,\n        COUNT\\(material_vendor_selections\\) as material_vendor_sel_count,\n        COUNT\\(parent_cr_id\\) as parent_cr_count,\n        COUNT\\(submission_group_id\\) as submission_group_count\n    FROM change_requests\n    WHERE is_deleted = false;\n\"\"\"\"\"\"\\)\n\nresult = cursor.fetchone\\(\\)\n\nprint\\(''=''*80\\)\nprint\\(''CHANGE_REQUESTS COLUMN USAGE ANALYSIS \\(Development Database\\)''\\)\nprint\\(''=''*80\\)\nprint\\(f''Total Change Requests: {result[0]}''\\)\nprint\\(\\)\nprint\\(''Column Usage \\(non-NULL count\\):''\\)\nprint\\(''-''*80\\)\nprint\\(f''  mep_approved_by_user_id: {result[1]} records''\\)\nprint\\(f''  mep_approved_by_name: {result[2]} records''\\)\nprint\\(f''  mep_approval_date: {result[3]} records''\\)\nprint\\(f''  vendor_whatsapp_sent_at: {result[4]} records''\\)\nprint\\(f''  vendor_email_sent_date: {result[5]} records''\\)\nprint\\(f''  delivery_routing: {result[6]} records''\\)\nprint\\(f''  vendor_delivered_to_store: {result[7]} records \\(TRUE count\\)''\\)\nprint\\(f''  material_vendor_selections: {result[8]} records''\\)\nprint\\(f''  parent_cr_id: {result[9]} records \\(sub-CRs\\)''\\)\nprint\\(f''  submission_group_id: {result[10]} records''\\)\nprint\\(''=''*80\\)\n\ncursor.close\\(\\)\nconn.close\\(\\)\n\")",
      "Bash(DATABASE_URL=\"postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev\\\\$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres\" python:*)",
      "Bash(python -c \"\nimport psycopg2\n\nconn = psycopg2.connect\\(''postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres''\\)\ncursor = conn.cursor\\(\\)\n\n# Get total count\ncursor.execute\\(''SELECT COUNT\\(*\\) FROM change_requests WHERE is_deleted = false''\\)\ntotal_count = cursor.fetchone\\(\\)[0]\n\n# Get all columns\ncursor.execute\\(\"\"\"\"\"\"\n    SELECT column_name \n    FROM information_schema.columns\n    WHERE table_name = ''change_requests''\n    AND column_name NOT IN \\(''cr_id'', ''created_at'', ''updated_at'', ''is_deleted''\\)\n    ORDER BY column_name;\n\"\"\"\"\"\"\\)\n\ncolumns = [row[0] for row in cursor.fetchall\\(\\)]\n\nprint\\(''=''*100\\)\nprint\\(f''CHECKING {len\\(columns\\)} COLUMNS IN change_requests TABLE''\\)\nprint\\(f''Total Records: {total_count} \\(excluding deleted\\)''\\)\nprint\\(''=''*100\\)\nprint\\(\\)\n\nunused_columns = []\nlow_usage_columns = []\n\nfor col in columns:\n    # Count non-null values\n    cursor.execute\\(f''SELECT COUNT\\({col}\\) FROM change_requests WHERE is_deleted = false AND {col} IS NOT NULL''\\)\n    non_null_count = cursor.fetchone\\(\\)[0]\n    \n    # For boolean/default columns, check if they have non-default values\n    if non_null_count == 0:\n        unused_columns.append\\(\\(col, non_null_count, 0.0\\)\\)\n    elif non_null_count < total_count * 0.1:  # Less than 10% usage\n        low_usage_columns.append\\(\\(col, non_null_count, \\(non_null_count/total_count\\)*100\\)\\)\n\nprint\\(''❌ COMPLETELY UNUSED COLUMNS \\(0% usage - NEVER used\\):''\\)\nprint\\(''-''*100\\)\nif unused_columns:\n    for col, count, pct in sorted\\(unused_columns\\):\n        print\\(f''  ❌ {col:<50} {count}/{total_count} records \\({pct:.1f}%\\)''\\)\nelse:\n    print\\(''  \\(None found\\)''\\)\n\nprint\\(\\)\nprint\\(''⚠️  LOW USAGE COLUMNS \\(< 10% usage\\):''\\)\nprint\\(''-''*100\\)\nif low_usage_columns:\n    for col, count, pct in sorted\\(low_usage_columns, key=lambda x: x[1]\\):\n        print\\(f''  ⚠️  {col:<50} {count}/{total_count} records \\({pct:.1f}%\\)''\\)\nelse:\n    print\\(''  \\(None found\\)''\\)\n\nprint\\(\\)\nprint\\(''=''*100\\)\nprint\\(f''SUMMARY:''\\)\nprint\\(f''  Total Columns Checked: {len\\(columns\\)}''\\)\nprint\\(f''  Completely Unused: {len\\(unused_columns\\)}''\\)\nprint\\(f''  Low Usage: {len\\(low_usage_columns\\)}''\\)\nprint\\(f''  Well Used: {len\\(columns\\) - len\\(unused_columns\\) - len\\(low_usage_columns\\)}''\\)\nprint\\(''=''*100\\)\n\ncursor.close\\(\\)\nconn.close\\(\\)\n\")",
      "Bash(DATABASE_URL=\"postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev\\\\$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres\" python3:*)",
      "Bash(DATABASE_URL=\"postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres\" venv/bin/python test_validation.py)",
      "Bash(PGPASSWORD=\"Meterkol\\\\$2025\" psql:*)",
      "Bash(python -c \"\nimport psycopg2\n\nconn = psycopg2.connect\\(''postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres''\\)\ncursor = conn.cursor\\(\\)\n\n# Get total count\ncursor.execute\\(''SELECT COUNT\\(*\\) FROM change_requests WHERE is_deleted = false''\\)\ntotal_count = cursor.fetchone\\(\\)[0]\n\n# Check all overhead-related columns\noverhead_columns = [\n    ''item_overhead_allocated'',\n    ''item_overhead_consumed_before'',\n    ''item_overhead_available'',\n    ''overhead_consumed'',\n    ''overhead_balance_impact'',\n    ''original_overhead_allocated'',\n    ''original_overhead_used'',\n    ''original_overhead_remaining'',\n    ''original_overhead_percentage'',\n    ''original_profit_percentage'',\n    ''new_overhead_remaining'',\n    ''percentage_of_item_overhead'',\n    ''profit_impact'',\n    ''new_base_cost'',\n    ''new_total_cost'',\n    ''is_over_budget'',\n    ''cost_increase_amount'',\n    ''cost_increase_percentage''\n]\n\nprint\\(''=''*100\\)\nprint\\(''OVERHEAD & FINANCIAL COLUMNS USAGE ANALYSIS''\\)\nprint\\(''=''*100\\)\nprint\\(f''Total Records: {total_count}''\\)\nprint\\(\\)\n\nunused = []\nused = []\n\nfor col in overhead_columns:\n    # Count records where column has non-zero/non-null value\n    cursor.execute\\(f''''''\n        SELECT COUNT\\(*\\) \n        FROM change_requests \n        WHERE is_deleted = false \n        AND {col} IS NOT NULL \n        AND {col} != 0\n    ''''''\\)\n    non_zero_count = cursor.fetchone\\(\\)[0]\n    \n    percentage = \\(non_zero_count / total_count * 100\\) if total_count > 0 else 0\n    \n    if non_zero_count == 0:\n        unused.append\\(\\(col, non_zero_count, percentage\\)\\)\n    else:\n        used.append\\(\\(col, non_zero_count, percentage\\)\\)\n\nprint\\(''❌ OVERHEAD COLUMNS - NEVER USED \\(Always NULL or 0\\):''\\)\nprint\\(''-''*100\\)\nif unused:\n    for col, count, pct in unused:\n        print\\(f''  ❌ {col:<50} {count}/{total_count} \\({pct:.1f}%\\)''\\)\nelse:\n    print\\(''  \\(All overhead columns are being used!\\)''\\)\n\nprint\\(\\)\nprint\\(''✅ OVERHEAD COLUMNS - ACTIVELY USED:''\\)\nprint\\(''-''*100\\)\nif used:\n    for col, count, pct in sorted\\(used, key=lambda x: x[1], reverse=True\\):\n        print\\(f''  ✅ {col:<50} {count}/{total_count} \\({pct:.1f}%\\)''\\)\n\nprint\\(\\)\nprint\\(''=''*100\\)\nprint\\(f''SUMMARY:''\\)\nprint\\(f''  Total Overhead Columns: {len\\(overhead_columns\\)}''\\)\nprint\\(f''  Unused \\(always 0/NULL\\): {len\\(unused\\)}''\\)\nprint\\(f''  Used: {len\\(used\\)}''\\)\nprint\\(''=''*100\\)\n\ncursor.close\\(\\)\nconn.close\\(\\)\n\")",
      "Bash(python -c \"\nimport psycopg2\n\nconn = psycopg2.connect\\(''postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres''\\)\ncursor = conn.cursor\\(\\)\n\n# Get total count\ncursor.execute\\(''SELECT COUNT\\(*\\) FROM change_requests WHERE is_deleted = false''\\)\ntotal_count = cursor.fetchone\\(\\)[0]\n\n# Numeric overhead columns\nnumeric_overhead_columns = [\n    ''item_overhead_allocated'',\n    ''item_overhead_consumed_before'',\n    ''item_overhead_available'',\n    ''overhead_consumed'',\n    ''overhead_balance_impact'',\n    ''original_overhead_allocated'',\n    ''original_overhead_used'',\n    ''original_overhead_remaining'',\n    ''original_overhead_percentage'',\n    ''original_profit_percentage'',\n    ''new_overhead_remaining'',\n    ''percentage_of_item_overhead'',\n    ''profit_impact'',\n    ''new_base_cost'',\n    ''new_total_cost'',\n    ''cost_increase_amount'',\n    ''cost_increase_percentage''\n]\n\nprint\\(''=''*100\\)\nprint\\(''OVERHEAD & FINANCIAL COLUMNS USAGE ANALYSIS''\\)\nprint\\(''=''*100\\)\nprint\\(f''Total Records: {total_count}''\\)\nprint\\(\\)\n\nunused = []\nused = []\n\nfor col in numeric_overhead_columns:\n    # Count records where column has non-zero/non-null value\n    cursor.execute\\(f''''''\n        SELECT COUNT\\(*\\) \n        FROM change_requests \n        WHERE is_deleted = false \n        AND {col} IS NOT NULL \n        AND {col} != 0\n    ''''''\\)\n    non_zero_count = cursor.fetchone\\(\\)[0]\n    \n    percentage = \\(non_zero_count / total_count * 100\\) if total_count > 0 else 0\n    \n    if non_zero_count == 0:\n        unused.append\\(\\(col, non_zero_count, percentage\\)\\)\n    else:\n        used.append\\(\\(col, non_zero_count, percentage\\)\\)\n\n# Check is_over_budget separately \\(boolean\\)\ncursor.execute\\(''''''\n    SELECT COUNT\\(*\\) \n    FROM change_requests \n    WHERE is_deleted = false \n    AND is_over_budget = true\n''''''\\)\nover_budget_count = cursor.fetchone\\(\\)[0]\nover_budget_pct = \\(over_budget_count / total_count * 100\\) if total_count > 0 else 0\n\nprint\\(''❌ OVERHEAD COLUMNS - NEVER USED \\(Always NULL or 0\\):''\\)\nprint\\(''-''*100\\)\nif unused:\n    for col, count, pct in unused:\n        print\\(f''  ❌ {col:<50} {count}/{total_count} \\({pct:.1f}%\\)''\\)\nelse:\n    print\\(''  ✅ ALL overhead columns have data!''\\)\n\nprint\\(\\)\nprint\\(''✅ OVERHEAD COLUMNS - ACTIVELY USED:''\\)\nprint\\(''-''*100\\)\nif used:\n    for col, count, pct in sorted\\(used, key=lambda x: x[1], reverse=True\\):\n        print\\(f''  ✅ {col:<50} {count}/{total_count} \\({pct:.1f}%\\)''\\)\n\nprint\\(\\)\nprint\\(f''  ✅ is_over_budget \\(boolean\\)                        {over_budget_count}/{total_count} TRUE \\({over_budget_pct:.1f}%\\)''\\)\n\nprint\\(\\)\nprint\\(''=''*100\\)\nprint\\(f''SUMMARY:''\\)\nprint\\(f''  Total Overhead Columns: {len\\(numeric_overhead_columns\\) + 1}''\\)\nprint\\(f''  Unused \\(always 0/NULL\\): {len\\(unused\\)}''\\)\nprint\\(f''  Used: {len\\(used\\) + 1}''\\)\nprint\\(''=''*100\\)\n\ncursor.close\\(\\)\nconn.close\\(\\)\n\")",
      "Bash(DATABASE_URL='postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres' python -c \"\nfrom migrations.remove_unused_columns_dev import run_migration\nrun_migration\\(\\)\n\")",
      "Bash(python -c \"\nimport psycopg2\n\nconn = psycopg2.connect\\(''postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres''\\)\ncursor = conn.cursor\\(\\)\n\n# Count columns before and after\ncursor.execute\\(\"\"\"\"\"\"\n    SELECT COUNT\\(*\\) as total_columns\n    FROM information_schema.columns\n    WHERE table_name = ''change_requests'';\n\"\"\"\"\"\"\\)\n\ncolumn_count = cursor.fetchone\\(\\)[0]\n\nprint\\(''=''*80\\)\nprint\\(''CLEANUP VERIFICATION - change_requests TABLE''\\)\nprint\\(''=''*80\\)\nprint\\(f''Total Columns Remaining: {column_count}''\\)\nprint\\(\\)\nprint\\(''Cleanup Summary:''\\)\nprint\\(''  Original: ~96 columns''\\)\nprint\\(''  Removed: 26 columns''\\)\nprint\\(f''  Current: {column_count} columns''\\)\nprint\\(f''  Reduction: {\\(26/96\\)*100:.1f}% smaller''\\)\nprint\\(''=''*80\\)\n\ncursor.close\\(\\)\nconn.close\\(\\)\n\")",
      "Bash(DATABASE_URL='postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres' python3:*)",
      "Bash(DATABASE_URL='postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres' venv/bin/python3:*)",
      "Bash(DATABASE_URL='postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres' python3 -c \"\nimport psycopg2\nimport os\n\nconn = psycopg2.connect\\(os.getenv\\(''DATABASE_URL''\\)\\)\ncursor = conn.cursor\\(\\)\n\n# Fix the status by trimming whitespace\ncursor.execute\\(''''''UPDATE po_child SET status = TRIM\\(status\\) WHERE id = 5''''''\\)\nconn.commit\\(\\)\n\ncursor.execute\\(''''''SELECT id, status, length\\(status\\) FROM po_child WHERE id = 5''''''\\)\nresult = cursor.fetchone\\(\\)\nif result:\n    print\\(f''✅ Fixed! ID: {result[0]}, Status: [{result[1]}], Length: {result[2]}''\\)\n\ncursor.close\\(\\)\nconn.close\\(\\)\n\")",
      "Bash(DATABASE_URL='postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres' python3 -c \"\nimport psycopg2\nimport os\n\nconn = psycopg2.connect\\(os.getenv\\(''DATABASE_URL''\\)\\)\ncursor = conn.cursor\\(\\)\n\n# Fix the status by replacing it completely\ncursor.execute\\(''''''UPDATE po_child SET status = ''vendor_approved'' WHERE id = 5''''''\\)\nconn.commit\\(\\)\n\ncursor.execute\\(''''''SELECT id, status, length\\(status\\) FROM po_child WHERE id = 5''''''\\)\nresult = cursor.fetchone\\(\\)\nif result:\n    print\\(f''✅ Fixed! ID: {result[0]}, Status: [{result[1]}], Length: {result[2]}''\\)\n\ncursor.close\\(\\)\nconn.close\\(\\)\n\")",
      "Bash(npx tsc --noEmit)",
      "Bash(PGPASSWORD=\"${DATABASE_PASSWORD}\" psql:*)",
      "Bash(python -c \" from models.po_child import POChild import inspect print\\(inspect.getsource\\(POChild\\)\\) \")",
      "Bash(python -m pytest:*)",
      "Bash(npx ts-node:*)",
      "Bash(node scripts/create-storage-bucket.js:*)",
      "Bash(cut:*)",
      "Bash(python3 -c \" import ast import os import sys def check_file\\(filepath\\): try: with open\\(filepath, ''r'', encoding=''utf-8''\\) as f: content = f.read\\(\\) tree = ast.parse\\(content\\) # Get all imported names imports = set\\(\\) for node in ast.walk\\(tree\\): if isinstance\\(node, ast.Import\\): for alias in node.names: imports.add\\(alias.asname or alias.name\\) elif isinstance\\(node, ast.ImportFrom\\): for alias in node.names: imports.add\\(alias.asname or alias.name\\) # Get all used names used = set\\(\\) for node in ast.walk\\(tree\\): if isinstance\\(node, ast.Name\\): used.add\\(node.id\\) elif isinstance\\(node, ast.Attribute\\): if isinstance\\(node.value, ast.Name\\): used.add\\(node.value.id\\) unused = imports - used if unused: print\\(f''{filepath}: {unused}''\\) except: pass for root, dirs, files in os.walk\\(''controllers''\\): for file in files: if file.endswith\\(''.py''\\): check_file\\(os.path.join\\(root, file\\)\\) \")",
      "Bash(DATABASE_URL='postgresql://postgres.jfskcxansfwxnlaqiiwn:Meterkol$2025@aws-0-ap-south-1.pooler.supabase.com:6543/postgres' python migrations/add_supplier_notes_to_po_child.py)",
      "Bash(DATABASE_URL='postgresql://postgres.jfskcxansfwxnlaqiiwn:Meterkol$2025@aws-0-ap-south-1.pooler.supabase.com:6543/postgres' python3 migrations/add_supplier_notes_to_po_child.py)",
      "Bash(DATABASE_URL='postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres' python -c \"\nfrom sqlalchemy import create_engine, text\nimport os\n\nengine = create_engine\\(os.environ[''DATABASE_URL'']\\)\nwith engine.connect\\(\\) as conn:\n    result = conn.execute\\(text\\(''SELECT id, parent_cr_id, suffix, vendor_selection_status, is_deleted FROM po_child WHERE vendor_selection_status = \\\\''pending_td_approval\\\\'' AND is_deleted = false LIMIT 10''\\)\\)\n    rows = result.fetchall\\(\\)\n    print\\(f''Found {len\\(rows\\)} records:''\\)\n    for row in rows:\n        print\\(f''  id={row[0]}, parent_cr_id={row[1]}, suffix={row[2]}, status={row[3]}, deleted={row[4]}''\\)\n\")",
      "Bash(DATABASE_URL='postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres' python -c \"\nfrom sqlalchemy import create_engine, text\nimport os\n\nengine = create_engine\\(os.environ[''DATABASE_URL'']\\)\nwith engine.connect\\(\\) as conn:\n    result = conn.execute\\(text\\(''SELECT cr.cr_id, cr.assigned_to_buyer_user_id, cr.assigned_to_buyer_name FROM change_requests cr WHERE cr.cr_id = 41''\\)\\)\n    row = result.fetchone\\(\\)\n    if row:\n        print\\(f''CR-{row[0]} assigned to buyer_id={row[1]}, buyer_name={row[2]}''\\)\n    else:\n        print\\(''CR not found''\\)\n\")",
      "Bash(python app.py:*)",
      "Bash(timeout 10 npm run dev:*)",
      "Bash(git diff:*)",
      "Bash(python migrations/drop_supplier_notes_columns.py:*)",
      "Bash(wc:*)",
      "Bash(for f in utils/*.py)",
      "Bash(do python3 -m py_compile \"$f\")",
      "Bash(for f in models/*.py routes/*.py services/*.py)",
      "Bash(git -C /home/development1/Desktop/MeterSquare ls-files:*)",
      "Bash(PGPASSWORD='Rameshdev$08' psql:*)",
      "Bash(venv/bin/python3:*)",
      "Bash(python check_delivery_notes.py:*)",
      "Bash(tail:*)",
      "Bash(pgrep:*)",
      "Bash(ss -tlnp:*)",
      "Bash(python -c:*)",
      "Bash(DATABASE_URL=\"postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres\" python migrations/add_grouped_materials_to_imr.py)",
      "Bash(DATABASE_URL=\"postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres\" python migrations/add_grouped_materials_to_imr.py)",
      "Bash(DATABASE_URL=\"postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres\" python3 -c \"\nimport psycopg2\nfrom psycopg2.extras import RealDictCursor\n\nconn = psycopg2.connect\\(''postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres''\\)\ncursor = conn.cursor\\(cursor_factory=RealDictCursor\\)\n\nprint\\(''=== DEV DATABASE - Checking POChildren with routed_to_store but no IMR ===''\\)\nprint\\(\\)\n\n# Find POChildren that are routed_to_store but have no IMR\ncursor.execute\\(''''''\n    SELECT pc.id, pc.status, pc.parent_cr_id, pc.materials_count\n    FROM po_children pc\n    WHERE pc.status = ''routed_to_store''\n    AND pc.is_deleted = false\n    AND NOT EXISTS \\(\n        SELECT 1 FROM internal_inventory_material_requests imr \n        WHERE imr.po_child_id = pc.id\n    \\)\n''''''\\)\nstuck = cursor.fetchall\\(\\)\n\nif stuck:\n    print\\(f''Found {len\\(stuck\\)} stuck POChildren \\(routed_to_store but no IMR\\):''\\)\n    for row in stuck:\n        print\\(f''  - POChild {row[\"\"id\"\"]}: status={row[\"\"status\"\"]}, CR={row[\"\"parent_cr_id\"\"]}''\\)\n    \n    # Reset them\n    ids = [row[''id''] for row in stuck]\n    cursor.execute\\(''''''\n        UPDATE po_children \n        SET status = ''vendor_approved''\n        WHERE id = ANY\\(%s\\)\n    '''''', \\(ids,\\)\\)\n    conn.commit\\(\\)\n    print\\(\\)\n    print\\(f''Reset {len\\(stuck\\)} POChildren back to vendor_approved''\\)\nelse:\n    print\\(''No stuck POChildren found in DEV database''\\)\n\ncursor.close\\(\\)\nconn.close\\(\\)\n\")",
      "Bash(DATABASE_URL=\"postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres\" python3:*)",
      "Bash(DATABASE_URL=\"postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres\" python3 -c \"\nimport psycopg2\nfrom psycopg2.extras import RealDictCursor\n\nconn = psycopg2.connect\\(''postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres''\\)\ncursor = conn.cursor\\(cursor_factory=RealDictCursor\\)\n\nprint\\(''=== DEV DATABASE - Checking POChildren with routed_to_store but no IMR ===''\\)\nprint\\(\\)\n\n# Find POChildren that are routed_to_store but have no IMR\ncursor.execute\\(''''''\n    SELECT pc.id, pc.status, pc.parent_cr_id, pc.materials_count\n    FROM po_child pc\n    WHERE pc.status = ''routed_to_store''\n    AND pc.is_deleted = false\n    AND NOT EXISTS \\(\n        SELECT 1 FROM internal_inventory_material_requests imr \n        WHERE imr.po_child_id = pc.id\n    \\)\n''''''\\)\nstuck = cursor.fetchall\\(\\)\n\nif stuck:\n    print\\(f''Found {len\\(stuck\\)} stuck POChildren \\(routed_to_store but no IMR\\):''\\)\n    for row in stuck:\n        print\\(f''  - POChild {row[\"\"id\"\"]}: status={row[\"\"status\"\"]}, CR={row[\"\"parent_cr_id\"\"]}''\\)\n    \n    # Reset them\n    ids = [row[''id''] for row in stuck]\n    cursor.execute\\(''''''\n        UPDATE po_child \n        SET status = ''vendor_approved''\n        WHERE id = ANY\\(%s\\)\n    '''''', \\(ids,\\)\\)\n    conn.commit\\(\\)\n    print\\(\\)\n    print\\(f''Reset {len\\(stuck\\)} POChildren back to vendor_approved''\\)\nelse:\n    print\\(''No stuck POChildren found in DEV database''\\)\n\ncursor.close\\(\\)\nconn.close\\(\\)\n\")",
      "Bash(DATABASE_URL=\"postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres\" python3 -c \"\nimport psycopg2\nfrom psycopg2.extras import RealDictCursor\n\nconn = psycopg2.connect\\(''postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres''\\)\ncursor = conn.cursor\\(cursor_factory=RealDictCursor\\)\n\n# Check BOQ table columns\ncursor.execute\\(''''''\n    SELECT column_name\n    FROM information_schema.columns\n    WHERE table_name = ''boq''\n    ORDER BY ordinal_position\n''''''\\)\ncolumns = cursor.fetchall\\(\\)\nprint\\(''BOQ Table Columns:''\\)\nfor col in columns:\n    print\\(f''  {col[\"\"column_name\"\"]}''\\)\n\ncursor.close\\(\\)\nconn.close\\(\\)\n\")",
      "Bash(source backend/venv/bin/activate)",
      "Bash(python migrations/create_labour_management_tables.py:*)",
      "Bash(PGPASSWORD='Meterkol$2025' psql -h aws-1-ap-south-1.pooler.supabase.com -U postgres.cbzdvghmrpsolryzdpxi -d postgres -p 6543 -c \"\n-- Check all workers\nSELECT worker_id, worker_code, full_name, hourly_rate, status FROM workers WHERE is_deleted = false ORDER BY worker_id;\n\")",
      "Bash(python investigate_missing_boqs.py:*)",
      "Bash(python check_chck5_labour.py:*)",
      "Bash(python consolidate_labour_roles.py:*)",
      "Bash(chmod:*)",
      "Bash(rm:*)",
      "Bash(git add:*)",
      "Bash(DEV_DATABASE_URL=\"postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres\" DATABASE_URL=\"$DEV_DATABASE_URL\" python check_worker_skills.py)",
      "Bash(DEV_DATABASE_URL=\"postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres\" DATABASE_URL=\"$DEV_DATABASE_URL\" python check_assignments.py)",
      "Bash(DEV_DATABASE_URL=\"postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres\" DATABASE_URL=\"$DEV_DATABASE_URL\" python fix_assignments_now.py)",
      "Bash(DEV_DATABASE_URL=\"postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres\" python debug_assignment.py)",
      "Bash(DEV_DATABASE_URL=\"postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres\" DATABASE_URL=\"$DEV_DATABASE_URL\" python -c \"\nfrom sqlalchemy import create_engine, text\nimport os\n\nengine = create_engine\\(os.getenv\\(''DATABASE_URL''\\)\\)\n\nwith engine.connect\\(\\) as conn:\n    # Check locked attendance count\n    result = conn.execute\\(text\\(''''''\n        SELECT \n            COUNT\\(*\\) as total_locked,\n            COUNT\\(CASE WHEN requisition_id IS NOT NULL THEN 1 END\\) as with_requisition,\n            COUNT\\(CASE WHEN requisition_id IS NULL THEN 1 END\\) as without_requisition\n        FROM daily_attendance\n        WHERE approval_status = ''locked''\n          AND is_deleted = FALSE\n          AND attendance_date >= ''2025-12-01''\n          AND attendance_date <= ''2026-01-06''\n    ''''''\\)\\)\n    \n    row = result.fetchone\\(\\)\n    print\\(f''Total Locked Attendance: {row[0]}''\\)\n    print\\(f''With Requisition: {row[1]}''\\)\n    print\\(f''Without Requisition \\(hidden by filter\\): {row[2]}''\\)\n    \n    if row[0] == 0:\n        print\\(''\\\\n❌ NO LOCKED ATTENDANCE FOUND!''\\)\n        print\\(''This is why the page shows \"\"No payroll data\"\"''\\)\n    elif row[2] > 0 and row[1] == 0:\n        print\\(''\\\\n⚠️  ALL locked attendance has NO requisition_id!''\\)\n        print\\(''The filter is hiding all data because we excluded workers without requisitions.''\\)\n\")",
      "Bash(DEV_DATABASE_URL=\"postgresql://postgres.cbzdvghmrpsolryzdpxi:Meterkol$2025@aws-1-ap-south-1.pooler.supabase.com:6543/postgres\" DATABASE_URL=\"$DEV_DATABASE_URL\" python:*)",
      "Bash(claude mcp list:*)",
      "Bash(git log:*)",
      "Bash(backend/venv/bin/python:*)",
      "Bash(PGPASSWORD='metersquare_db_2024' psql -h aws-0-ap-south-1.pooler.supabase.com -U postgres.pqiufyqiqwzjkmglhgct -d postgres -p 6543 -c \"SELECT cr_id, status, delivery_routing, purchase_completed_by_name FROM change_requests WHERE cr_id IN \\(540, 541\\) ORDER BY cr_id;\")",
      "Bash(python -c \"\nimport os\nos.environ[''DATABASE_URL''] = ''postgresql://postgres.pqiufyqiqwzjkmglhgct:metersquare_db_2024@aws-0-ap-south-1.pooler.supabase.com:6543/postgres''\nfrom sqlalchemy import create_engine, text\nengine = create_engine\\(os.environ[''DATABASE_URL'']\\)\nwith engine.connect\\(\\) as conn:\n    result = conn.execute\\(text\\(''SELECT cr_id, status, delivery_routing, requested_by_role FROM change_requests WHERE cr_id IN \\(540, 541\\) ORDER BY cr_id''\\)\\)\n    for row in result:\n        print\\(f''CR-{row[0]}: status={row[1]}, routing={row[2]}, role={row[3]}''\\)\n\")",
      "Bash(python fix_missing_imr.py:*)",
      "Bash(python -c \"\nimport os\nos.environ[''DATABASE_URL''] = ''postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres''\nfrom sqlalchemy import create_engine, text, inspect\nengine = create_engine\\(os.environ[''DATABASE_URL'']\\)\ninspector = inspect\\(engine\\)\ntables = inspector.get_table_names\\(\\)\nproject_tables = [t for t in tables if ''project'' in t.lower\\(\\)]\nprint\\(''Project-related tables:'', project_tables\\)\n\")",
      "Bash(python -c \"\nimport os\nos.environ[''DATABASE_URL''] = ''postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres''\nfrom sqlalchemy import create_engine, text\nengine = create_engine\\(os.environ[''DATABASE_URL'']\\)\nwith engine.connect\\(\\) as conn:\n    result = conn.execute\\(text\\(''''''\n        SELECT\n            request_id,\n            cr_id,\n            material_name,\n            quantity,\n            status,\n            final_destination_site,\n            created_at::date\n        FROM internal_inventory_material_requests\n        WHERE cr_id IN \\(540, 541\\)\n        ORDER BY request_id DESC\n    ''''''\\)\\)\n    print\\(''Internal Material Requests for CR-540 and CR-541:''\\)\n    print\\(''=''*80\\)\n    for row in result:\n        print\\(f''Request #{row[0]}: CR-{row[1]} | {row[2]} \\(Qty: {row[3]}\\) | {row[4]} | {row[5]} | Created: {row[6]}''\\)\n\")",
      "Bash(python -c \"\nimport os\nos.environ[''DATABASE_URL''] = ''postgresql://postgres.wgddnoiakkoskbbkbygw:Rameshdev$08@aws-0-ap-south-1.pooler.supabase.com:6543/postgres''\nfrom sqlalchemy import create_engine, text\nengine = create_engine\\(os.environ[''DATABASE_URL'']\\)\nwith engine.connect\\(\\) as conn:\n    # Get the internal material requests\n    result = conn.execute\\(text\\(''''''\n        SELECT\n            request_id,\n            cr_id,\n            material_name,\n            quantity,\n            status,\n            source_type,\n            vendor_delivery_confirmed,\n            created_at::date,\n            request_send\n        FROM internal_inventory_material_requests\n        WHERE request_id IN \\(16, 18, 19\\)\n        ORDER BY request_id\n    ''''''\\)\\)\n    print\\(''Internal Material Requests:''\\)\n    print\\(''=''*100\\)\n    for row in result:\n        print\\(f''#{row[0]}: CR-{row[1]} | {row[2]} \\({row[3]}\\) | Status: {row[4]} | Source: {row[5]} | Vendor Confirmed: {row[6]} | Request Sent: {row[8]} | Created: {row[7]}''\\)\n    \n    # Get the change request statuses  \n    print\\(''\\\\n'' + ''=''*100\\)\n    print\\(''Change Request Statuses:''\\)\n    print\\(''=''*100\\)\n    result2 = conn.execute\\(text\\(''''''\n        SELECT\n            cr_id,\n            status,\n            delivery_routing,\n            store_request_status,\n            purchase_completed_by_name,\n            purchase_completion_date::date\n        FROM change_requests\n        WHERE cr_id IN \\(540, 541\\)\n        ORDER BY cr_id\n    ''''''\\)\\)\n    for row in result2:\n        print\\(f''CR-{row[0]}: Status={row[1]} | Routing={row[2]} | Store Status={row[3]} | Completed By={row[4]} | Date={row[5]}''\\)\n\")",
      "Read(//home/development1/Desktop/MeterSquare/frontend/**)",
      "Bash(git commit:*)",
      "Bash(so that who are requested and payment lock all they can see easily\".\n\nCo-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>\nEOF\n\\)\")"
    ],
    "deny": [],
    "ask": []
  },
  "hooks": {
    "PostToolUse": [
      {
        "matcher": "Edit",
        "hooks": [
          {
            "type": "prompt",
            "prompt": "A code edit was just made. Remind the developer: 'Code changed! Consider running the codebase-auditor agent to review changes for errors, duplicates, and best practices.'",
            "statusMessage": "Checking code change..."
          }
        ]
      },
      {
        "matcher": "Write",
        "hooks": [
          {
            "type": "prompt",
            "prompt": "A new file was just written. Remind the developer: 'New file created! Consider running the codebase-auditor agent to review for errors, duplicates, and best practices.'",
            "statusMessage": "Checking new file..."
          }
        ]
      }
    ]
  }
}
